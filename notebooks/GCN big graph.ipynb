{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/manohar/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh, ArpackNoConvergence\n",
    "from keras import activations, initializers, constraints\n",
    "from keras import regularizers\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def load_data(path=\"data/cora/\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    print('Dataset has {} nodes, {} edges, {} features.'.format(adj.shape[0], edges.shape[0], features.shape[1]))\n",
    "\n",
    "    return features.todense(), adj, labels\n",
    "\n",
    "\n",
    "def normalize_adj(adj, symmetric=True):\n",
    "    if symmetric:\n",
    "        d = sp.diags(np.power(np.array(adj.sum(1)), -0.5).flatten(), 0)\n",
    "        a_norm = adj.dot(d).transpose().dot(d).tocsr()\n",
    "    else:\n",
    "        d = sp.diags(np.power(np.array(adj.sum(1)), -1).flatten(), 0)\n",
    "        a_norm = d.dot(adj).tocsr()\n",
    "    return a_norm\n",
    "\n",
    "\n",
    "def preprocess_adj(adj, symmetric=True):\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = normalize_adj(adj, symmetric)\n",
    "    return adj\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "\n",
    "def get_splits(y):\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "    y_train = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_val = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_test = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_train[idx_train] = y[idx_train]\n",
    "    y_val[idx_val] = y[idx_val]\n",
    "    y_test[idx_test] = y[idx_test]\n",
    "    train_mask = sample_mask(idx_train, y.shape[0])\n",
    "    return y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask\n",
    "\n",
    "\n",
    "def categorical_crossentropy(preds, labels):\n",
    "    return np.mean(-np.log(np.extract(labels, preds)))\n",
    "\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return np.mean(np.equal(np.argmax(labels, 1), np.argmax(preds, 1)))\n",
    "\n",
    "\n",
    "def evaluate_preds(preds, labels, indices):\n",
    "\n",
    "    split_loss = list()\n",
    "    split_acc = list()\n",
    "\n",
    "    for y_split, idx_split in zip(labels, indices):\n",
    "        split_loss.append(categorical_crossentropy(preds[idx_split], y_split[idx_split]))\n",
    "        split_acc.append(accuracy(preds[idx_split], y_split[idx_split]))\n",
    "\n",
    "    return split_loss, split_acc\n",
    "\n",
    "\n",
    "def normalized_laplacian(adj, symmetric=True):\n",
    "    adj_normalized = normalize_adj(adj, symmetric)\n",
    "    laplacian = sp.eye(adj.shape[0]) - adj_normalized\n",
    "    return laplacian\n",
    "\n",
    "\n",
    "def rescale_laplacian(laplacian):\n",
    "    try:\n",
    "        print('Calculating largest eigenvalue of normalized graph Laplacian...')\n",
    "        largest_eigval = eigsh(laplacian, 1, which='LM', return_eigenvectors=False)[0]\n",
    "    except ArpackNoConvergence:\n",
    "        print('Eigenvalue calculation did not converge! Using largest_eigval=2 instead.')\n",
    "        largest_eigval = 2\n",
    "\n",
    "    scaled_laplacian = (2. / largest_eigval) * laplacian - sp.eye(laplacian.shape[0])\n",
    "    return scaled_laplacian\n",
    "\n",
    "\n",
    "def chebyshev_polynomial(X, k):\n",
    "    \"\"\"Calculate Chebyshev polynomials up to order k. Return a list of sparse matrices.\"\"\"\n",
    "    print(\"Calculating Chebyshev polynomials up to order {}...\".format(k))\n",
    "\n",
    "    T_k = list()\n",
    "    T_k.append(sp.eye(X.shape[0]).tocsr())\n",
    "    T_k.append(X)\n",
    "\n",
    "    def chebyshev_recurrence(T_k_minus_one, T_k_minus_two, X):\n",
    "        X_ = sp.csr_matrix(X, copy=True)\n",
    "        return 2 * X_.dot(T_k_minus_one) - T_k_minus_two\n",
    "\n",
    "    for i in range(2, k+1):\n",
    "        T_k.append(chebyshev_recurrence(T_k[-1], T_k[-2], X))\n",
    "\n",
    "    return T_k\n",
    "\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphConvolution(Layer):\n",
    "    \"\"\"Basic graph convolution layer as in https://arxiv.org/abs/1609.02907\"\"\"\n",
    "    def __init__(self, units, support=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(GraphConvolution, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.support = support\n",
    "        assert support >= 1\n",
    "\n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        features_shape = input_shapes[0]\n",
    "        output_shape = (features_shape[0], self.units)\n",
    "        return output_shape  # (batch_size, output_dim)\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        features_shape = input_shapes[0]\n",
    "        assert len(features_shape) == 2\n",
    "        input_dim = features_shape[1]\n",
    "\n",
    "        self.kernel = self.add_weight(shape=(input_dim * self.support,\n",
    "                                             self.units),\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias is not None:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        features = inputs[0]\n",
    "        basis = inputs[1:]\n",
    "\n",
    "        supports = list()\n",
    "        for i in range(self.support):\n",
    "            supports.append(K.dot(basis[i], features))\n",
    "        supports = K.concatenate(supports, axis=1)\n",
    "        output = K.dot(supports, self.kernel)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        return self.activation(output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'units': self.units,\n",
    "                  'support': self.support,\n",
    "                  'activation': activations.serialize(self.activation),\n",
    "                  'use_bias': self.use_bias,\n",
    "                  'kernel_initializer': initializers.serialize(\n",
    "                      self.kernel_initializer),\n",
    "                  'bias_initializer': initializers.serialize(\n",
    "                      self.bias_initializer),\n",
    "                  'kernel_regularizer': regularizers.serialize(\n",
    "                      self.kernel_regularizer),\n",
    "                  'bias_regularizer': regularizers.serialize(\n",
    "                      self.bias_regularizer),\n",
    "                  'activity_regularizer': regularizers.serialize(\n",
    "                      self.activity_regularizer),\n",
    "                  'kernel_constraint': constraints.serialize(\n",
    "                      self.kernel_constraint),\n",
    "                  'bias_constraint': constraints.serialize(self.bias_constraint)\n",
    "        }\n",
    "\n",
    "        base_config = super(GraphConvolution, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n",
      "Using local pooling filters...\n",
      "WARNING:tensorflow:From /Users/manohar/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d39c05a917eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m               verbose=0)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Predict on full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3275\u001b[0m         \u001b[0mtensor_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m         array_vals.append(np.asarray(value,\n\u001b[0;32m-> 3277\u001b[0;31m                                      dtype=tensor_type.as_numpy_dtype))\n\u001b[0m\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define parameters\n",
    "DATASET = 'cora'\n",
    "FILTER = 'localpool'  # 'chebyshev'\n",
    "MAX_DEGREE = 2  # maximum polynomial degree\n",
    "SYM_NORM = True  # symmetric (True) vs. left-only (False) normalization\n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "\n",
    "# Get data\n",
    "X, A, y = load_data(path='/Users/manohar/Desktop/sunandan cause effect/keras-gcn-master/kegra/data/cora/', dataset=DATASET)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)\n",
    "\n",
    "# Normalize X\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "\n",
    "if FILTER == 'localpool':\n",
    "    \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "    print('Using local pooling filters...')\n",
    "    A_ = preprocess_adj(A, SYM_NORM)\n",
    "    support = 1\n",
    "    graph = [X, A_]\n",
    "    G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]\n",
    "\n",
    "elif FILTER == 'chebyshev':\n",
    "    \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "    print('Using Chebyshev polynomial basis filters...')\n",
    "    L = normalized_laplacian(A, SYM_NORM)\n",
    "    L_scaled = rescale_laplacian(L)\n",
    "    T_k = chebyshev_polynomial(L_scaled, MAX_DEGREE)\n",
    "    support = MAX_DEGREE + 1\n",
    "    graph = [X]+T_k\n",
    "    G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True) for _ in range(support)]\n",
    "\n",
    "else:\n",
    "    raise Exception('Invalid filter type.')\n",
    "\n",
    "X_in = Input(shape=(X.shape[1],))\n",
    "\n",
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], \n",
    "              epochs=1, \n",
    "              shuffle=False, \n",
    "              verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "      \"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-071357a427de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "graph.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), dtype=np.dtype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "# build graph\n",
    "idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "idx_map = {j: i for i, j in enumerate(idx)}\n",
    "edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
    "edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                 dtype=np.int32).reshape(edges_unordered.shape)\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
    "\n",
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "print('Dataset has {} nodes, {} edges, {} features.'.format(adj.shape[0], edges.shape[0], features.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     35,    1033],\n",
       "       [     35,  103482],\n",
       "       [     35,  103515],\n",
       "       ...,\n",
       "       [ 853118, 1140289],\n",
       "       [ 853155,  853118],\n",
       "       [ 954315, 1155073]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 163,  402],\n",
       "       [ 163,  659],\n",
       "       [ 163, 1696],\n",
       "       ...,\n",
       "       [1887, 2258],\n",
       "       [1902, 1887],\n",
       "       [ 837, 1686]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes=[x[0] for x in idx_features_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case_Based',\n",
       " 'Genetic_Algorithms',\n",
       " 'Neural_Networks',\n",
       " 'Probabilistic_Methods',\n",
       " 'Reinforcement_Learning',\n",
       " 'Rule_Learning',\n",
       " 'Theory'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[-1] for x in idx_features_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=[]\n",
    "for x in idx_features_labels:\n",
    "    if x[-1]=='Neural_Networks':\n",
    "        c.append('g')\n",
    "    elif x[-1]=='Rule_Learning':\n",
    "        c.append('r')\n",
    "    elif x[-1]=='Reinforcement_Learning':\n",
    "        c.append('b')\n",
    "    elif x[-1]=='Genetic_Algorithms':\n",
    "        c.append('y')\n",
    "    elif x[-1]=='Case_Based':\n",
    "        c.append('v')\n",
    "    elif x[-1]=='Theory':\n",
    "        c.append('o')\n",
    "    elif x[-1]=='Probabilistic_Methods':\n",
    "        c.append('br')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument must be a mpl color, a sequence of mpl colors or a sequence of numbers, not ['g', 'r', 'b', 'b', 'br', 'br', 'o', 'g', 'g', 'o', 'g', 'y', 'br', 'v', 'g', 'g', 'b', 'g', 'g', 'g', 'o', 'b', 'y', 'br', 'b', 'o', 'g', 'br', 'g', 'r', 'v', 'g', 'v', 'g', 'b', 'b', 'g', 'b', 'y', 'b', 'o', 'br', 'y', 'g', 'v', 'b', 'g', 'v', 'br', 'v', 'v', 'br', 'o', 'y', 'o', 'y', 'o', 'b', 'g', 'g', 'b', 'v', 'br', 'b', 'v', 'y', 'v', 'br', 'g', 'v', 'o', 'br', 'g', 'b', 'br', 'v', 'br', 'g', 'o', 'o', 'g', 'br', 'b', 'g', 'br', 'b', 'r', 'r', 'o', 'o', 'g', 'g', 'b', 'br', 'br', 'br', 'v', 'g', 'o', 'br', 'y', 'g', 'g', 'b', 'g', 'br', 'r', 'br', 'br', 'o', 'g', 'g', 'g', 'g', 'o', 'br', 'v', 'br', 'b', 'r', 'y', 'g', 'g', 'g', 'g', 'g', 'br', 'g', 'b', 'y', 'o', 'br', 'b', 'g', 'g', 'r', 'r', 'br', 'br', 'y', 'o', 'y', 'g', 'g', 'g', 'y', 'g', 'v', 'b', 'v', 'v', 'o', 'g', 'g', 'g', 'br', 'r', 'o', 'r', 'o', 'g', 'br', 'b', 'y', 'o', 'r', 'v', 'b', 'y', 'g', 'br', 'o', 'v', 'b', 'g', 'g', 'r', 'o', 'r', 'g', 'g', 'o', 'br', 'v', 'r', 'br', 'b', 'g', 'y', 'y', 'g', 'y', 'g', 'g', 'g', 'r', 'r', 'b', 'g', 'o', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'o', 'y', 'b', 'br', 'g', 'b', 'g', 'v', 'r', 'g', 'br', 'y', 'b', 'v', 'v', 'r', 'r', 'v', 'g', 'o', 'y', 'g', 'g', 'v', 'g', 'g', 'g', 'g', 'v', 'y', 'g', 'b', 'y', 'g', 'o', 'y', 'g', 'v', 'br', 'b', 'br', 'r', 'br', 'o', 'b', 'g', 'g', 'o', 'v', 'g', 'g', 'v', 'br', 'g', 'v', 'g', 'o', 'y', 'v', 'o', 'g', 'g', 'br', 'g', 'g', 'y', 'b', 'br', 'br', 'b', 'br', 'br', 'br', 'b', 'g', 'g', 'v', 'v', 'r', 'o', 'v', 'v', 'y', 'g', 'br', 'g', 'b', 'b', 'o', 'g', 'b', 'o', 'v', 'g', 'r', 'v', 'g', 'b', 'b', 'r', 'o', 'y', 'g', 'g', 'br', 'v', 'r', 'g', 'r', 'o', 'v', 'o', 'g', 'b', 'o', 'o', 'br', 'br', 'br', 'br', 'g', 'y', 'g', 'g', 'br', 'b', 'o', 'r', 'g', 'g', 'g', 'br', 'g', 'g', 'br', 'y', 'r', 'br', 'g', 'br', 'r', 'g', 'g', 'g', 'br', 'g', 'g', 'g', 'g', 'y', 'br', 'g', 'g', 'y', 'g', 'g', 'g', 'g', 'g', 'b', 'g', 'g', 'b', 'br', 'y', 'r', 'b', 'o', 'br', 'g', 'o', 'r', 'y', 'o', 'o', 'g', 'g', 'b', 'g', 'g', 'g', 'br', 'y', 'g', 'br', 'g', 'g', 'y', 'r', 'g', 'br', 'g', 'o', 'br', 'y', 'y', 'g', 'g', 'g', 'g', 'g', 'g', 'b', 'g', 'b', 'g', 'v', 'y', 'br', 'r', 'o', 'br', 'g', 'o', 'y', 'br', 'o', 'b', 'r', 'g', 'r', 'br', 'o', 'o', 'r', 'r', 'v', 'g', 'o', 'g', 'o', 'g', 'b', 'v', 'br', 'g', 'g', 'v', 'b', 'g', 'y', 'v', 'br', 'b', 'br', 'o', 'v', 'b', 'o', 'v', 'g', 'o', 'b', 'g', 'g', 'b', 'br', 'b', 'b', 'br', 'br', 'g', 'v', 'b', 'b', 'b', 'g', 'y', 'g', 'b', 'v', 'v', 'g', 'o', 'v', 'b', 'br', 'br', 'v', 'g', 'o', 'g', 'b', 'br', 'b', 'y', 'g', 'br', 'g', 'o', 'br', 'br', 'b', 'g', 'b', 'g', 'g', 'g', 'b', 'o', 'o', 'r', 'br', 'br', 'g', 'br', 'o', 'br', 'g', 'o', 'o', 'g', 'g', 'r', 'o', 'y', 'g', 'o', 'g', 'g', 'g', 'g', 'y', 'g', 'br', 'br', 'v', 'o', 'g', 'y', 'y', 'v', 'v', 'v', 'g', 'v', 'g', 'g', 'y', 'g', 'b', 'o', 'o', 'b', 'b', 'g', 'b', 'o', 'o', 'br', 'br', 'b', 'o', 'g', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'o', 'g', 'o', 'g', 'br', 'o', 'b', 'g', 'br', 'v', 'g', 'v', 'v', 'v', 'v', 'br', 'r', 'g', 'g', 'b', 'g', 'g', 'o', 'g', 'v', 'v', 'g', 'o', 'r', 'r', 'g', 'g', 'b', 'y', 'v', 'g', 'g', 'y', 'g', 'g', 'g', 'g', 'g', 'v', 'g', 'o', 'o', 'g', 'g', 'o', 'br', 'g', 'b', 'g', 'br', 'o', 'g', 'g', 'g', 'g', 'v', 'g', 'g', 'br', 'b', 'v', 'o', 'b', 'br', 'o', 'br', 'o', 'br', 'br', 'v', 'b', 'br', 'br', 'br', 'g', 'v', 'b', 'g', 'r', 'b', 'r', 'g', 'b', 'b', 'y', 'g', 'o', 'br', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'r', 'v', 'b', 'o', 'g', 'g', 'r', 'g', 'g', 'g', 'v', 'g', 'y', 'b', 'v', 'br', 'g', 'v', 'g', 'b', 'y', 'v', 'b', 'o', 'g', 'g', 'o', 'g', 'br', 'g', 'b', 'o', 'g', 'g', 'g', 'br', 'g', 'o', 'r', 'g', 'g', 'o', 'br', 'y', 'br', 'y', 'br', 'g', 'y', 'g', 'g', 'g', 'y', 'o', 'br', 'g', 'br', 'g', 'y', 'y', 'br', 'g', 'g', 'o', 'b', 'b', 'r', 'g', 'g', 'b', 'b', 'o', 'g', 'br', 'y', 'y', 'g', 'g', 'g', 'br', 'b', 'b', 'g', 'v', 'g', 'g', 'y', 'r', 'y', 'y', 'br', 'v', 'o', 'o', 'g', 'y', 'y', 'g', 'o', 'br', 'y', 'g', 'g', 'br', 'b', 'g', 'b', 'br', 'br', 'o', 'g', 'y', 'y', 'g', 'v', 'g', 'v', 'o', 'br', 'br', 'y', 'o', 'o', 'o', 'y', 'o', 'o', 'g', 'g', 'o', 'v', 'y', 'v', 'br', 'y', 'b', 'g', 'v', 'b', 'g', 'g', 'g', 'y', 'g', 'y', 'g', 'y', 'g', 'v', 'v', 'v', 'g', 'g', 'o', 'g', 'v', 'v', 'g', 'br', 'g', 'g', 'g', 'v', 'g', 'y', 'g', 'v', 'o', 'r', 'br', 'g', 'g', 'br', 'b', 'b', 'y', 'g', 'y', 'o', 'o', 'r', 'br', 'br', 'br', 'o', 'y', 'br', 'y', 'v', 'v', 'o', 'y', 'o', 'v', 'g', 'g', 'o', 'g', 'g', 'b', 'br', 'b', 'br', 'g', 'g', 'g', 'b', 'o', 'r', 'g', 'b', 'y', 'g', 'b', 'v', 'o', 'o', 'g', 'o', 'br', 'br', 'g', 'br', 'br', 'r', 'br', 'br', 'br', 'br', 'br', 'g', 'y', 'v', 'y', 'o', 'br', 'br', 'g', 'g', 'g', 'br', 'y', 'o', 'g', 'br', 'g', 'br', 'g', 'br', 'g', 'g', 'g', 'g', 'v', 'v', 'o', 'g', 'o', 'v', 'v', 'br', 'g', 'o', 'o', 'b', 'y', 'y', 'b', 'v', 'y', 'g', 'y', 'y', 'y', 'y', 'br', 'br', 'g', 'v', 'g', 'g', 'br', 'v', 'br', 'y', 'br', 'o', 'y', 'o', 'y', 'y', 'r', 'y', 'g', 'r', 'y', 'y', 'y', 'o', 'g', 'br', 'y', 'br', 'y', 'br', 'y', 'g', 'br', 'o', 'g', 'g', 'g', 'v', 'y', 'v', 'v', 'br', 'v', 'br', 'b', 'g', 'g', 'v', 'v', 'br', 'v', 'y', 'br', 'r', 'br', 'br', 'o', 'v', 'v', 'o', 'o', 'g', 'o', 'r', 'r', 'y', 'r', 'r', 'b', 'br', 'g', 'br', 'y', 'g', 'y', 'o', 'br', 'g', 'g', 'g', 'o', 'o', 'o', 'o', 'g', 'br', 'y', 'g', 'o', 'v', 'y', 'y', 'y', 'g', 'g', 'v', 'v', 'g', 'g', 'g', 'g', 'b', 'v', 'v', 'v', 'r', 'o', 'g', 'g', 'o', 'y', 'g', 'g', 'g', 'g', 'g', 'y', 'r', 'o', 'y', 'br', 'y', 'g', 'g', 'g', 'y', 'y', 'r', 'g', 'r', 'o', 'g', 'br', 'y', 'br', 'g', 'g', 'r', 'r', 'br', 'v', 'r', 'br', 'br', 'g', 'v', 'g', 'g', 'o', 'g', 'g', 'o', 'y', 'br', 'y', 'y', 'g', 'v', 'r', 'g', 'o', 'o', 'y', 'v', 'br', 'o', 'y', 'v', 'g', 'y', 'y', 'g', 'g', 'y', 'g', 'g', 'g', 'v', 'v', 'v', 'o', 'v', 'v', 'y', 'br', 'g', 'y', 'y', 'o', 'br', 'y', 'o', 'y', 'b', 'v', 'y', 'y', 'br', 'y', 'y', 'g', 'g', 'g', 'br', 'v', 'g', 'g', 'r', 'v', 'y', 'v', 'v', 'br', 'g', 'br', 'y', 'o', 'o', 'br', 'v', 'o', 'r', 'o', 'y', 'br', 'g', 'o', 'g', 'br', 'o', 'o', 'y', 'g', 'r', 'y', 'g', 'r', 'o', 'r', 'b', 'y', 'o', 'br', 'o', 'g', 'o', 'g', 'o', 'b', 'b', 'v', 'g', 'g', 'o', 'o', 'o', 'g', 'br', 'b', 'g', 'y', 'y', 'y', 'y', 'r', 'v', 'v', 'g', 'v', 'b', 'v', 'v', 'y', 'b', 'y', 'y', 'g', 'y', 'g', 'o', 'y', 'y', 'r', 'o', 'b', 'g', 'y', 'y', 'y', 'v', 'r', 'o', 'o', 'o', 'o', 'g', 'br', 'br', 'g', 'g', 'r', 'g', 'g', 'g', 'v', 'y', 'g', 'g', 'g', 'b', 'g', 'br', 'r', 'y', 'g', 'r', 'o', 'y', 'g', 'v', 'y', 'g', 'g', 'o', 'br', 'o', 'o', 'r', 'g', 'o', 'y', 'r', 'br', 'y', 'v', 'y', 'o', 'g', 'g', 'g', 'g', 'g', 'y', 'br', 'br', 'g', 'o', 'br', 'r', 'g', 'br', 'g', 'o', 'r', 'g', 'y', 'g', 'r', 'v', 'y', 'v', 'y', 'o', 'g', 'br', 'o', 'o', 'y', 'r', 'g', 'b', 'g', 'b', 'v', 'g', 'y', 'g', 'g', 'o', 'g', 'br', 'y', 'br', 'r', 'g', 'o', 'y', 'y', 'y', 'y', 'y', 'br', 'br', 'o', 'br', 'o', 'g', 'g', 'g', 'o', 'v', 'v', 'g', 'br', 'v', 'b', 'v', 'y', 'g', 'y', 'v', 'v', 'g', 'br', 'o', 'g', 'o', 'o', 'y', 'o', 'o', 'g', 'g', 'v', 'v', 'y', 'r', 'y', 'br', 'g', 'g', 'br', 'b', 'v', 'b', 'y', 'y', 'br', 'g', 'g', 'g', 'v', 'o', 'g', 'o', 'g', 'o', 'y', 'y', 'br', 'g', 'y', 'y', 'br', 'g', 'g', 'o', 'v', 'g', 'br', 'y', 'g', 'g', 'v', 'y', 'y', 'y', 'g', 'v', 'v', 'br', 'br', 'v', 'g', 'g', 'br', 'v', 'g', 'g', 'g', 'y', 'br', 'v', 'br', 'r', 'r', 'g', 'g', 'y', 'o', 'r', 'g', 'br', 'br', 'b', 'y', 'b', 'y', 'r', 'b', 'o', 'r', 'g', 'b', 'v', 'o', 'g', 'g', 'g', 'v', 'g', 'y', 'o', 'g', 'br', 'b', 'o', 'g', 'g', 'br', 'g', 'v', 'y', 'y', 'o', 'o', 'g', 'g', 'g', 'y', 'y', 'v', 'y', 'g', 'br', 'br', 'g', 'y', 'o', 'v', 'o', 'g', 'r', 'g', 'g', 'r', 'g', 'o', 'o', 'g', 'g', 'y', 'v', 'v', 'v', 'g', 'o', 'g', 'br', 'br', 'br', 'o', 'br', 'br', 'g', 'g', 'o', 'g', 'br', 'v', 'o', 'b', 'y', 'g', 'y', 'r', 'g', 'o', 'o', 'y', 'g', 'br', 'g', 'br', 'r', 'b', 'y', 'v', 'br', 'y', 'v', 'v', 'y', 'v', 'g', 'r', 'b', 'y', 'v', 'br', 'y', 'br', 'b', 'g', 'br', 'br', 'o', 'g', 'v', 'v', 'v', 'br', 'v', 'b', 'y', 'g', 'b', 'o', 'g', 'y', 'g', 'y', 'o', 'o', 'v', 'r', 'v', 'y', 'y', 'b', 'v', 'y', 'o', 'y', 'r', 'g', 'y', 'b', 'br', 'g', 'v', 'b', 'o', 'r', 'y', 'b', 'y', 'g', 'g', 'br', 'y', 'o', 'r', 'v', 'y', 'b', 'g', 'g', 'br', 'y', 'g', 'o', 'g', 'o', 'br', 'r', 'g', 'y', 'g', 'br', 'br', 'g', 'b', 'v', 'o', 'br', 'r', 'v', 'r', 'g', 'br', 'b', 'v', 'r', 'y', 'g', 'g', 'y', 'b', 'g', 'g', 'v', 'v', 'g', 'y', 'g', 'v', 'br', 'v', 'b', 'g', 'g', 'y', 'o', 'v', 'b', 'y', 'r', 'g', 'v', 'br', 'g', 'g', 'g', 'o', 'g', 'br', 'o', 'y', 'y', 'g', 'v', 'br', 'g', 'g', 'o', 'y', 'o', 'g', 'y', 'v', 'y', 'g', 'g', 'o', 'r', 'v', 'br', 'br', 'o', 'r', 'y', 'r', 'b', 'y', 'y', 'y', 'y', 'o', 'b', 'y', 'v', 'y', 'g', 'v', 'v', 'g', 'g', 'o', 'b', 'g', 'o', 'v', 'v', 'o', 'g', 'g', 'b', 'o', 'br', 'br', 'y', 'br', 'y', 'g', 'y', 'r', 'r', 'br', 'br', 'g', 'g', 'r', 'o', 'y', 'y', 'y', 'br', 'g', 'br', 'y', 'v', 'y', 'y', 'y', 'o', 'y', 'b', 'br', 'y', 'g', 'y', 'g', 'br', 'o', 'br', 'r', 'g', 'v', 'g', 'b', 'g', 'y', 'br', 'b', 'br', 'g', 'br', 'o', 'g', 'br', 'br', 'g', 'b', 'b', 'y', 'g', 'y', 'g', 'g', 'g', 'y', 'r', 'br', 'g', 'b', 'b', 'r', 'b', 'br', 'y', 'y', 'o', 'g', 'g', 'g', 'y', 'b', 'o', 'g', 'g', 'g', 'y', 'y', 'g', 'y', 'br', 'g', 'br', 'br', 'v', 'v', 'g', 'y', 'o', 'v', 'g', 'g', 'g', 'g', 'g', 'g', 'b', 'g', 'g', 'r', 'g', 'g', 'g', 'o', 'o', 'g', 'y', 'o', 'b', 'br', 'v', 'y', 'y', 'o', 'y', 'o', 'y', 'r', 'br', 'y', 'y', 'b', 'br', 'v', 'b', 'b', 'g', 'g', 'o', 'r', 'y', 'g', 'br', 'o', 'v', 'v', 'br', 'br', 'o', 'b', 'v', 'o', 'o', 'o', 'v', 'g', 'g', 'g', 'br', 'g', 'br', 'g', 'y', 'g', 'g', 'o', 'br', 'v', 'y', 'g', 'y', 'r', 'v', 'y', 'g', 'g', 'g', 'g', 'o', 'g', 'y', 'g', 'v', 'g', 'br', 'g', 'g', 'o', 'br', 'br', 'br', 'br', 'g', 'g', 'v', 'y', 'br', 'br', 'br', 'br', 'br', 'y', 'g', 'br', 'g', 'g', 'g', 'y', 'o', 'r', 'g', 'y', 'br', 'g', 'o', 'y', 'br', 'g', 'g', 'g', 'y', 'y', 'g', 'br', 'br', 'g', 'y', 'br', 'br', 'g', 'y', 'br', 'br', 'y', 'r', 'br', 'y', 'g', 'g', 'g', 'y', 'v', 'g', 'g', 'b', 'r', 'r', 'b', 'y', 'y', 'g', 'r', 'o', 'r', 'o', 'y', 'g', 'o', 'g', 'b', 'g', 'y', 'br', 'y', 'g', 'b', 'v', 'br', 'br', 'b', 'y', 'g', 'br', 'br', 'y', 'y', 'o', 'v', 'br', 'v', 'g', 'br', 'br', 'br', 'br', 'br', 'g', 'g', 'g', 'y', 'br', 'y', 'br', 'y', 'o', 'o', 'o', 'b', 'br', 'r', 'v', 'o', 'o', 'g', 'b', 'o', 'br', 'br', 'b', 'g', 'g', 'g', 'br', 'g', 'g', 'br', 'g', 'b', 'o', 'g', 'y', 'o', 'r', 'g', 'br', 'v', 'o', 'v', 'v', 'y', 'o', 'g', 'g', 'g', 'g', 'r', 'g', 'y', 'v', 'g', 'g', 'b', 'v', 'o', 'o', 'y', 'g', 'v', 'y', 'o', 'v', 'v', 'v', 'br', 'br', 'y', 'o', 'o', 'g', 'br', 'r', 'v', 'g', 'o', 'v', 'v', 'br', 'y', 'br', 'r', 'o', 'br', 'y', 'g', 'g', 'g', 'y', 'y', 'br', 'y', 'g', 'v', 'o', 'g', 'br', 'g', 'r', 'br', 'o', 'o', 'r', 'y', 'y', 'y', 'y', 'g', 'r', 'g', 'br', 'g', 'o', 'y', 'g', 'o', 'br', 'br', 'y', 'g', 'b', 'g', 'g', 'g', 'v', 'v', 'g', 'g', 'r', 'br', 'v', 'g', 'y', 'v', 'r', 'y', 'o', 'g', 'br', 'v', 'br', 'y', 'br', 'o', 'r', 'g', 'br', 'o', 'o', 'g', 'br', 'r', 'b', 'v', 'y', 'br', 'g', 'g', 'o', 'v', 'r', 'br', 'br', 'br', 'g', 'r', 'br', 'y', 'br', 'br', 'o', 'br', 'y', 'r', 'o', 'y', 'b', 'y', 'g', 'y', 'g', 'b', 'o', 'g', 'o', 'b', 'v', 'g', 'g', 'g', 'r', 'r', 'r', 'g', 'y', 'y', 'r', 'r', 'y', 'o', 'o', 'y', 'y', 'g', 'y', 'g', 'y', 'y', 'y', 'b', 'br', 'b', 'o', 'y', 'g', 'r', 'g', 'v', 'y', 'r', 'g', 'br', 'y', 'br', 'b', 'g', 'g', 'o', 'y', 'g', 'g', 'r', 'g', 'v', 'y', 'g', 'br', 'br', 'g', 'y', 'y', 'g', 'r', 'br', 'br', 'g', 'v', 'v', 'o', 'g', 'y', 'y', 'y', 'y', 'y', 'r', 'y', 'y', 'g', 'y', 'g', 'y', 'g', 'y', 'g', 'g', 'y', 'y', 'br', 'y', 'g', 'y', 'g', 'y', 'g', 'o', 'y', 'g', 'v', 'y', 'g', 'g', 'y', 'g', 'r', 'g', 'g', 'br', 'y', 'br', 'br', 'v', 'r', 'r', 'br', 'br', 'v', 'y', 'y', 'o', 'y', 'v', 'r', 'br', 'y', 'v', 'g', 'b', 'g', 'g', 'v', 'b', 'v', 'br', 'r', 'br', 'g', 'o', 'y', 'y', 'br', 'v', 'o', 'g', 'g', 'br', 'o', 'g', 'o', 'o', 'b', 'o', 'y', 'o', 'y', 'o', 'y', 'g', 'g', 'g', 'v', 'r', 'g', 'br', 'o', 'br', 'g', 'o', 'o', 'y', 'br', 'g', 'o', 'g', 'g', 'y', 'o', 'g', 'o', 'g', 'g', 'v', 'o', 'y', 'br', 'y', 'v', 'r', 'br', 'o', 'b', 'v', 'g', 'v', 'v', 'g', 'g', 'br', 'g', 'br', 'g', 'y', 'br', 'g', 'g', 'g', 'br', 'g', 'g', 'g', 'g', 'br', 'g', 'o', 'y', 'g', 'g', 'v', 'y', 'g', 'v', 'v', 'g', 'br', 'y', 'v', 'br', 'g', 'b', 'y', 'b', 'g', 'g', 'b', 'b', 'g', 'g', 'v', 'br', 'br', 'o', 'br', 'br', 'br', 'g', 'o', 'r', 'br', 'r', 'g', 'br', 'y', 'b', 'r', 'b', 'g', 'br', 'g', 'r', 'b', 'g', 'g', 'g', 'r', 'b', 'br', 'b', 'g', 'y', 'v', 'g', 'r', 'r', 'y', 'g', 'b', 'g', 'o', 'br', 'g', 'br', 'g', 'br', 'br', 'br', 'br', 'br', 'v', 'v', 'o', 'br', 'g', 'y', 'v', 'b', 'v', 'br', 'o', 'o', 'g', 'y', 'y', 'b', 'o', 'v', 'o', 'v', 'b', 'g', 'o', 'br', 'v', 'y', 'g', 'br', 'r', 'b', 'o', 'g', 'g', 'g', 'g', 'g', 'g', 'v', 'g', 'y', 'g', 'br', 'g', 'o', 'o', 'br', 'o', 'y', 'g', 'br', 'y', 'y', 'g', 'y', 'y', 'v', 'y', 'g', 'g', 'br', 'br', 'g', 'r', 'o', 'br', 'g', 'br', 'br', 'g', 'r', 'g', 'b', 'g', 'g', 'r', 'g', 'y', 'g', 'br', 'v', 'g', 'br', 'v', 'o', 'g', 'r', 'b', 'g', 'g', 'y', 'o', 'v', 'g', 'br', 'br', 'o', 'br', 'g', 'y', 'y', 'v', 'br', 'g', 'v', 'g', 'g', 'g', 'g', 'br', 'g', 'br', 'g', 'br', 'br', 'g', 'o', 'v', 'g', 'o', 'g', 'v', 'b', 'r', 'br', 'r', 'br', 'r', 'br', 'v', 'g', 'g', 'br', 'v', 'y', 'g', 'y', 'g', 'r', 'g', 'y', 'v', 'g', 'v', 'g', 'r', 'g', 'g', 'g', 'y', 'v', 'g', 'v', 'r', 'o', 'g', 'br', 'g', 'v', 'o', 'y', 'g', 'v', 'o', 'b', 'b', 'y', 'g', 'g', 'o', 'br', 'v', 'r', 'y', 'y', 'g', 'r', 'y', 'g', 'y', 'o', 'v', 'y', 'b', 'g', 'r', 'r', 'o', 'v', 'o', 'br', 'b', 'v', 'o', 'v', 'y', 'br', 'br', 'g', 'r', 'y', 'v', 'b', 'y', 'r', 'br', 'g', 'g', 'g', 'y', 'g', 'o', 'g', 'br', 'g', 'br', 'g', 'g', 'br', 'g', 'g', 'o', 'g', 'b', 'y', 'o', 'o', 'g', 'v', 'br', 'o', 'o', 'o', 'br', 'br', 'br', 'br', 'g', 'y', 'y', 'y', 'y', 'v', 'g'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[1;32m   4284\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4285\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4286\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Suppress exception chaining of cache lookup failure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;31m# tuple color.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 'br'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b54085fdd49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py\u001b[0m in \u001b[0;36mdraw_networkx\u001b[0;34m(G, pos, arrows, with_labels, **kwds)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspring_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# default to spring layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0mnode_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_networkx_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0medge_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_networkx_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py\u001b[0m in \u001b[0;36mdraw_networkx_nodes\u001b[0;34m(G, pos, nodelist, node_size, node_color, node_shape, alpha, cmap, vmin, vmax, ax, linewidths, label, **kwds)\u001b[0m\n\u001b[1;32m    398\u001b[0m                                  \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                                  \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                                  label=label)\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mnode_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_zorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4452\u001b[0m             self._parse_scatter_color_args(\n\u001b[1;32m   4453\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4454\u001b[0;31m                 get_next_color_func=self._get_patches_for_fill.get_next_color)\n\u001b[0m\u001b[1;32m   4455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplotnonfinite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36m_parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xshape, yshape, get_next_color_func)\u001b[0m\n\u001b[1;32m   4304\u001b[0m                         \u001b[0;34m\"'c' argument must be a mpl color, a sequence of mpl \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m                         \u001b[0;34m\"colors or a sequence of numbers, not {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4306\u001b[0;31m                             \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# note: could be long depending on c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4307\u001b[0m                     )\n\u001b[1;32m   4308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument must be a mpl color, a sequence of mpl colors or a sequence of numbers, not ['g', 'r', 'b', 'b', 'br', 'br', 'o', 'g', 'g', 'o', 'g', 'y', 'br', 'v', 'g', 'g', 'b', 'g', 'g', 'g', 'o', 'b', 'y', 'br', 'b', 'o', 'g', 'br', 'g', 'r', 'v', 'g', 'v', 'g', 'b', 'b', 'g', 'b', 'y', 'b', 'o', 'br', 'y', 'g', 'v', 'b', 'g', 'v', 'br', 'v', 'v', 'br', 'o', 'y', 'o', 'y', 'o', 'b', 'g', 'g', 'b', 'v', 'br', 'b', 'v', 'y', 'v', 'br', 'g', 'v', 'o', 'br', 'g', 'b', 'br', 'v', 'br', 'g', 'o', 'o', 'g', 'br', 'b', 'g', 'br', 'b', 'r', 'r', 'o', 'o', 'g', 'g', 'b', 'br', 'br', 'br', 'v', 'g', 'o', 'br', 'y', 'g', 'g', 'b', 'g', 'br', 'r', 'br', 'br', 'o', 'g', 'g', 'g', 'g', 'o', 'br', 'v', 'br', 'b', 'r', 'y', 'g', 'g', 'g', 'g', 'g', 'br', 'g', 'b', 'y', 'o', 'br', 'b', 'g', 'g', 'r', 'r', 'br', 'br', 'y', 'o', 'y', 'g', 'g', 'g', 'y', 'g', 'v', 'b', 'v', 'v', 'o', 'g', 'g', 'g', 'br', 'r', 'o', 'r', 'o', 'g', 'br', 'b', 'y', 'o', 'r', 'v', 'b', 'y', 'g', 'br', 'o', 'v', 'b', 'g', 'g', 'r', 'o', 'r', 'g', 'g', 'o', 'br', 'v', 'r', 'br', 'b', 'g', 'y', 'y', 'g', 'y', 'g', 'g', 'g', 'r', 'r', 'b', 'g', 'o', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'o', 'y', 'b', 'br', 'g', 'b', 'g', 'v', 'r', 'g', 'br', 'y', 'b', 'v', 'v', 'r', 'r', 'v', 'g', 'o', 'y', 'g', 'g', 'v', 'g', 'g', 'g', 'g', 'v', 'y', 'g', 'b', 'y', 'g', 'o', 'y', 'g', 'v', 'br', 'b', 'br', 'r', 'br', 'o', 'b', 'g', 'g', 'o', 'v', 'g', 'g', 'v', 'br', 'g', 'v', 'g', 'o', 'y', 'v', 'o', 'g', 'g', 'br', 'g', 'g', 'y', 'b', 'br', 'br', 'b', 'br', 'br', 'br', 'b', 'g', 'g', 'v', 'v', 'r', 'o', 'v', 'v', 'y', 'g', 'br', 'g', 'b', 'b', 'o', 'g', 'b', 'o', 'v', 'g', 'r', 'v', 'g', 'b', 'b', 'r', 'o', 'y', 'g', 'g', 'br', 'v', 'r', 'g', 'r', 'o', 'v', 'o', 'g', 'b', 'o', 'o', 'br', 'br', 'br', 'br', 'g', 'y', 'g', 'g', 'br', 'b', 'o', 'r', 'g', 'g', 'g', 'br', 'g', 'g', 'br', 'y', 'r', 'br', 'g', 'br', 'r', 'g', 'g', 'g', 'br', 'g', 'g', 'g', 'g', 'y', 'br', 'g', 'g', 'y', 'g', 'g', 'g', 'g', 'g', 'b', 'g', 'g', 'b', 'br', 'y', 'r', 'b', 'o', 'br', 'g', 'o', 'r', 'y', 'o', 'o', 'g', 'g', 'b', 'g', 'g', 'g', 'br', 'y', 'g', 'br', 'g', 'g', 'y', 'r', 'g', 'br', 'g', 'o', 'br', 'y', 'y', 'g', 'g', 'g', 'g', 'g', 'g', 'b', 'g', 'b', 'g', 'v', 'y', 'br', 'r', 'o', 'br', 'g', 'o', 'y', 'br', 'o', 'b', 'r', 'g', 'r', 'br', 'o', 'o', 'r', 'r', 'v', 'g', 'o', 'g', 'o', 'g', 'b', 'v', 'br', 'g', 'g', 'v', 'b', 'g', 'y', 'v', 'br', 'b', 'br', 'o', 'v', 'b', 'o', 'v', 'g', 'o', 'b', 'g', 'g', 'b', 'br', 'b', 'b', 'br', 'br', 'g', 'v', 'b', 'b', 'b', 'g', 'y', 'g', 'b', 'v', 'v', 'g', 'o', 'v', 'b', 'br', 'br', 'v', 'g', 'o', 'g', 'b', 'br', 'b', 'y', 'g', 'br', 'g', 'o', 'br', 'br', 'b', 'g', 'b', 'g', 'g', 'g', 'b', 'o', 'o', 'r', 'br', 'br', 'g', 'br', 'o', 'br', 'g', 'o', 'o', 'g', 'g', 'r', 'o', 'y', 'g', 'o', 'g', 'g', 'g', 'g', 'y', 'g', 'br', 'br', 'v', 'o', 'g', 'y', 'y', 'v', 'v', 'v', 'g', 'v', 'g', 'g', 'y', 'g', 'b', 'o', 'o', 'b', 'b', 'g', 'b', 'o', 'o', 'br', 'br', 'b', 'o', 'g', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'o', 'g', 'o', 'g', 'br', 'o', 'b', 'g', 'br', 'v', 'g', 'v', 'v', 'v', 'v', 'br', 'r', 'g', 'g', 'b', 'g', 'g', 'o', 'g', 'v', 'v', 'g', 'o', 'r', 'r', 'g', 'g', 'b', 'y', 'v', 'g', 'g', 'y', 'g', 'g', 'g', 'g', 'g', 'v', 'g', 'o', 'o', 'g', 'g', 'o', 'br', 'g', 'b', 'g', 'br', 'o', 'g', 'g', 'g', 'g', 'v', 'g', 'g', 'br', 'b', 'v', 'o', 'b', 'br', 'o', 'br', 'o', 'br', 'br', 'v', 'b', 'br', 'br', 'br', 'g', 'v', 'b', 'g', 'r', 'b', 'r', 'g', 'b', 'b', 'y', 'g', 'o', 'br', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'r', 'v', 'b', 'o', 'g', 'g', 'r', 'g', 'g', 'g', 'v', 'g', 'y', 'b', 'v', 'br', 'g', 'v', 'g', 'b', 'y', 'v', 'b', 'o', 'g', 'g', 'o', 'g', 'br', 'g', 'b', 'o', 'g', 'g', 'g', 'br', 'g', 'o', 'r', 'g', 'g', 'o', 'br', 'y', 'br', 'y', 'br', 'g', 'y', 'g', 'g', 'g', 'y', 'o', 'br', 'g', 'br', 'g', 'y', 'y', 'br', 'g', 'g', 'o', 'b', 'b', 'r', 'g', 'g', 'b', 'b', 'o', 'g', 'br', 'y', 'y', 'g', 'g', 'g', 'br', 'b', 'b', 'g', 'v', 'g', 'g', 'y', 'r', 'y', 'y', 'br', 'v', 'o', 'o', 'g', 'y', 'y', 'g', 'o', 'br', 'y', 'g', 'g', 'br', 'b', 'g', 'b', 'br', 'br', 'o', 'g', 'y', 'y', 'g', 'v', 'g', 'v', 'o', 'br', 'br', 'y', 'o', 'o', 'o', 'y', 'o', 'o', 'g', 'g', 'o', 'v', 'y', 'v', 'br', 'y', 'b', 'g', 'v', 'b', 'g', 'g', 'g', 'y', 'g', 'y', 'g', 'y', 'g', 'v', 'v', 'v', 'g', 'g', 'o', 'g', 'v', 'v', 'g', 'br', 'g', 'g', 'g', 'v', 'g', 'y', 'g', 'v', 'o', 'r', 'br', 'g', 'g', 'br', 'b', 'b', 'y', 'g', 'y', 'o', 'o', 'r', 'br', 'br', 'br', 'o', 'y', 'br', 'y', 'v', 'v', 'o', 'y', 'o', 'v', 'g', 'g', 'o', 'g', 'g', 'b', 'br', 'b', 'br', 'g', 'g', 'g', 'b', 'o', 'r', 'g', 'b', 'y', 'g', 'b', 'v', 'o', 'o', 'g', 'o', 'br', 'br', 'g', 'br', 'br', 'r', 'br', 'br', 'br', 'br', 'br', 'g', 'y', 'v', 'y', 'o', 'br', 'br', 'g', 'g', 'g', 'br', 'y', 'o', 'g', 'br', 'g', 'br', 'g', 'br', 'g', 'g', 'g', 'g', 'v', 'v', 'o', 'g', 'o', 'v', 'v', 'br', 'g', 'o', 'o', 'b', 'y', 'y', 'b', 'v', 'y', 'g', 'y', 'y', 'y', 'y', 'br', 'br', 'g', 'v', 'g', 'g', 'br', 'v', 'br', 'y', 'br', 'o', 'y', 'o', 'y', 'y', 'r', 'y', 'g', 'r', 'y', 'y', 'y', 'o', 'g', 'br', 'y', 'br', 'y', 'br', 'y', 'g', 'br', 'o', 'g', 'g', 'g', 'v', 'y', 'v', 'v', 'br', 'v', 'br', 'b', 'g', 'g', 'v', 'v', 'br', 'v', 'y', 'br', 'r', 'br', 'br', 'o', 'v', 'v', 'o', 'o', 'g', 'o', 'r', 'r', 'y', 'r', 'r', 'b', 'br', 'g', 'br', 'y', 'g', 'y', 'o', 'br', 'g', 'g', 'g', 'o', 'o', 'o', 'o', 'g', 'br', 'y', 'g', 'o', 'v', 'y', 'y', 'y', 'g', 'g', 'v', 'v', 'g', 'g', 'g', 'g', 'b', 'v', 'v', 'v', 'r', 'o', 'g', 'g', 'o', 'y', 'g', 'g', 'g', 'g', 'g', 'y', 'r', 'o', 'y', 'br', 'y', 'g', 'g', 'g', 'y', 'y', 'r', 'g', 'r', 'o', 'g', 'br', 'y', 'br', 'g', 'g', 'r', 'r', 'br', 'v', 'r', 'br', 'br', 'g', 'v', 'g', 'g', 'o', 'g', 'g', 'o', 'y', 'br', 'y', 'y', 'g', 'v', 'r', 'g', 'o', 'o', 'y', 'v', 'br', 'o', 'y', 'v', 'g', 'y', 'y', 'g', 'g', 'y', 'g', 'g', 'g', 'v', 'v', 'v', 'o', 'v', 'v', 'y', 'br', 'g', 'y', 'y', 'o', 'br', 'y', 'o', 'y', 'b', 'v', 'y', 'y', 'br', 'y', 'y', 'g', 'g', 'g', 'br', 'v', 'g', 'g', 'r', 'v', 'y', 'v', 'v', 'br', 'g', 'br', 'y', 'o', 'o', 'br', 'v', 'o', 'r', 'o', 'y', 'br', 'g', 'o', 'g', 'br', 'o', 'o', 'y', 'g', 'r', 'y', 'g', 'r', 'o', 'r', 'b', 'y', 'o', 'br', 'o', 'g', 'o', 'g', 'o', 'b', 'b', 'v', 'g', 'g', 'o', 'o', 'o', 'g', 'br', 'b', 'g', 'y', 'y', 'y', 'y', 'r', 'v', 'v', 'g', 'v', 'b', 'v', 'v', 'y', 'b', 'y', 'y', 'g', 'y', 'g', 'o', 'y', 'y', 'r', 'o', 'b', 'g', 'y', 'y', 'y', 'v', 'r', 'o', 'o', 'o', 'o', 'g', 'br', 'br', 'g', 'g', 'r', 'g', 'g', 'g', 'v', 'y', 'g', 'g', 'g', 'b', 'g', 'br', 'r', 'y', 'g', 'r', 'o', 'y', 'g', 'v', 'y', 'g', 'g', 'o', 'br', 'o', 'o', 'r', 'g', 'o', 'y', 'r', 'br', 'y', 'v', 'y', 'o', 'g', 'g', 'g', 'g', 'g', 'y', 'br', 'br', 'g', 'o', 'br', 'r', 'g', 'br', 'g', 'o', 'r', 'g', 'y', 'g', 'r', 'v', 'y', 'v', 'y', 'o', 'g', 'br', 'o', 'o', 'y', 'r', 'g', 'b', 'g', 'b', 'v', 'g', 'y', 'g', 'g', 'o', 'g', 'br', 'y', 'br', 'r', 'g', 'o', 'y', 'y', 'y', 'y', 'y', 'br', 'br', 'o', 'br', 'o', 'g', 'g', 'g', 'o', 'v', 'v', 'g', 'br', 'v', 'b', 'v', 'y', 'g', 'y', 'v', 'v', 'g', 'br', 'o', 'g', 'o', 'o', 'y', 'o', 'o', 'g', 'g', 'v', 'v', 'y', 'r', 'y', 'br', 'g', 'g', 'br', 'b', 'v', 'b', 'y', 'y', 'br', 'g', 'g', 'g', 'v', 'o', 'g', 'o', 'g', 'o', 'y', 'y', 'br', 'g', 'y', 'y', 'br', 'g', 'g', 'o', 'v', 'g', 'br', 'y', 'g', 'g', 'v', 'y', 'y', 'y', 'g', 'v', 'v', 'br', 'br', 'v', 'g', 'g', 'br', 'v', 'g', 'g', 'g', 'y', 'br', 'v', 'br', 'r', 'r', 'g', 'g', 'y', 'o', 'r', 'g', 'br', 'br', 'b', 'y', 'b', 'y', 'r', 'b', 'o', 'r', 'g', 'b', 'v', 'o', 'g', 'g', 'g', 'v', 'g', 'y', 'o', 'g', 'br', 'b', 'o', 'g', 'g', 'br', 'g', 'v', 'y', 'y', 'o', 'o', 'g', 'g', 'g', 'y', 'y', 'v', 'y', 'g', 'br', 'br', 'g', 'y', 'o', 'v', 'o', 'g', 'r', 'g', 'g', 'r', 'g', 'o', 'o', 'g', 'g', 'y', 'v', 'v', 'v', 'g', 'o', 'g', 'br', 'br', 'br', 'o', 'br', 'br', 'g', 'g', 'o', 'g', 'br', 'v', 'o', 'b', 'y', 'g', 'y', 'r', 'g', 'o', 'o', 'y', 'g', 'br', 'g', 'br', 'r', 'b', 'y', 'v', 'br', 'y', 'v', 'v', 'y', 'v', 'g', 'r', 'b', 'y', 'v', 'br', 'y', 'br', 'b', 'g', 'br', 'br', 'o', 'g', 'v', 'v', 'v', 'br', 'v', 'b', 'y', 'g', 'b', 'o', 'g', 'y', 'g', 'y', 'o', 'o', 'v', 'r', 'v', 'y', 'y', 'b', 'v', 'y', 'o', 'y', 'r', 'g', 'y', 'b', 'br', 'g', 'v', 'b', 'o', 'r', 'y', 'b', 'y', 'g', 'g', 'br', 'y', 'o', 'r', 'v', 'y', 'b', 'g', 'g', 'br', 'y', 'g', 'o', 'g', 'o', 'br', 'r', 'g', 'y', 'g', 'br', 'br', 'g', 'b', 'v', 'o', 'br', 'r', 'v', 'r', 'g', 'br', 'b', 'v', 'r', 'y', 'g', 'g', 'y', 'b', 'g', 'g', 'v', 'v', 'g', 'y', 'g', 'v', 'br', 'v', 'b', 'g', 'g', 'y', 'o', 'v', 'b', 'y', 'r', 'g', 'v', 'br', 'g', 'g', 'g', 'o', 'g', 'br', 'o', 'y', 'y', 'g', 'v', 'br', 'g', 'g', 'o', 'y', 'o', 'g', 'y', 'v', 'y', 'g', 'g', 'o', 'r', 'v', 'br', 'br', 'o', 'r', 'y', 'r', 'b', 'y', 'y', 'y', 'y', 'o', 'b', 'y', 'v', 'y', 'g', 'v', 'v', 'g', 'g', 'o', 'b', 'g', 'o', 'v', 'v', 'o', 'g', 'g', 'b', 'o', 'br', 'br', 'y', 'br', 'y', 'g', 'y', 'r', 'r', 'br', 'br', 'g', 'g', 'r', 'o', 'y', 'y', 'y', 'br', 'g', 'br', 'y', 'v', 'y', 'y', 'y', 'o', 'y', 'b', 'br', 'y', 'g', 'y', 'g', 'br', 'o', 'br', 'r', 'g', 'v', 'g', 'b', 'g', 'y', 'br', 'b', 'br', 'g', 'br', 'o', 'g', 'br', 'br', 'g', 'b', 'b', 'y', 'g', 'y', 'g', 'g', 'g', 'y', 'r', 'br', 'g', 'b', 'b', 'r', 'b', 'br', 'y', 'y', 'o', 'g', 'g', 'g', 'y', 'b', 'o', 'g', 'g', 'g', 'y', 'y', 'g', 'y', 'br', 'g', 'br', 'br', 'v', 'v', 'g', 'y', 'o', 'v', 'g', 'g', 'g', 'g', 'g', 'g', 'b', 'g', 'g', 'r', 'g', 'g', 'g', 'o', 'o', 'g', 'y', 'o', 'b', 'br', 'v', 'y', 'y', 'o', 'y', 'o', 'y', 'r', 'br', 'y', 'y', 'b', 'br', 'v', 'b', 'b', 'g', 'g', 'o', 'r', 'y', 'g', 'br', 'o', 'v', 'v', 'br', 'br', 'o', 'b', 'v', 'o', 'o', 'o', 'v', 'g', 'g', 'g', 'br', 'g', 'br', 'g', 'y', 'g', 'g', 'o', 'br', 'v', 'y', 'g', 'y', 'r', 'v', 'y', 'g', 'g', 'g', 'g', 'o', 'g', 'y', 'g', 'v', 'g', 'br', 'g', 'g', 'o', 'br', 'br', 'br', 'br', 'g', 'g', 'v', 'y', 'br', 'br', 'br', 'br', 'br', 'y', 'g', 'br', 'g', 'g', 'g', 'y', 'o', 'r', 'g', 'y', 'br', 'g', 'o', 'y', 'br', 'g', 'g', 'g', 'y', 'y', 'g', 'br', 'br', 'g', 'y', 'br', 'br', 'g', 'y', 'br', 'br', 'y', 'r', 'br', 'y', 'g', 'g', 'g', 'y', 'v', 'g', 'g', 'b', 'r', 'r', 'b', 'y', 'y', 'g', 'r', 'o', 'r', 'o', 'y', 'g', 'o', 'g', 'b', 'g', 'y', 'br', 'y', 'g', 'b', 'v', 'br', 'br', 'b', 'y', 'g', 'br', 'br', 'y', 'y', 'o', 'v', 'br', 'v', 'g', 'br', 'br', 'br', 'br', 'br', 'g', 'g', 'g', 'y', 'br', 'y', 'br', 'y', 'o', 'o', 'o', 'b', 'br', 'r', 'v', 'o', 'o', 'g', 'b', 'o', 'br', 'br', 'b', 'g', 'g', 'g', 'br', 'g', 'g', 'br', 'g', 'b', 'o', 'g', 'y', 'o', 'r', 'g', 'br', 'v', 'o', 'v', 'v', 'y', 'o', 'g', 'g', 'g', 'g', 'r', 'g', 'y', 'v', 'g', 'g', 'b', 'v', 'o', 'o', 'y', 'g', 'v', 'y', 'o', 'v', 'v', 'v', 'br', 'br', 'y', 'o', 'o', 'g', 'br', 'r', 'v', 'g', 'o', 'v', 'v', 'br', 'y', 'br', 'r', 'o', 'br', 'y', 'g', 'g', 'g', 'y', 'y', 'br', 'y', 'g', 'v', 'o', 'g', 'br', 'g', 'r', 'br', 'o', 'o', 'r', 'y', 'y', 'y', 'y', 'g', 'r', 'g', 'br', 'g', 'o', 'y', 'g', 'o', 'br', 'br', 'y', 'g', 'b', 'g', 'g', 'g', 'v', 'v', 'g', 'g', 'r', 'br', 'v', 'g', 'y', 'v', 'r', 'y', 'o', 'g', 'br', 'v', 'br', 'y', 'br', 'o', 'r', 'g', 'br', 'o', 'o', 'g', 'br', 'r', 'b', 'v', 'y', 'br', 'g', 'g', 'o', 'v', 'r', 'br', 'br', 'br', 'g', 'r', 'br', 'y', 'br', 'br', 'o', 'br', 'y', 'r', 'o', 'y', 'b', 'y', 'g', 'y', 'g', 'b', 'o', 'g', 'o', 'b', 'v', 'g', 'g', 'g', 'r', 'r', 'r', 'g', 'y', 'y', 'r', 'r', 'y', 'o', 'o', 'y', 'y', 'g', 'y', 'g', 'y', 'y', 'y', 'b', 'br', 'b', 'o', 'y', 'g', 'r', 'g', 'v', 'y', 'r', 'g', 'br', 'y', 'br', 'b', 'g', 'g', 'o', 'y', 'g', 'g', 'r', 'g', 'v', 'y', 'g', 'br', 'br', 'g', 'y', 'y', 'g', 'r', 'br', 'br', 'g', 'v', 'v', 'o', 'g', 'y', 'y', 'y', 'y', 'y', 'r', 'y', 'y', 'g', 'y', 'g', 'y', 'g', 'y', 'g', 'g', 'y', 'y', 'br', 'y', 'g', 'y', 'g', 'y', 'g', 'o', 'y', 'g', 'v', 'y', 'g', 'g', 'y', 'g', 'r', 'g', 'g', 'br', 'y', 'br', 'br', 'v', 'r', 'r', 'br', 'br', 'v', 'y', 'y', 'o', 'y', 'v', 'r', 'br', 'y', 'v', 'g', 'b', 'g', 'g', 'v', 'b', 'v', 'br', 'r', 'br', 'g', 'o', 'y', 'y', 'br', 'v', 'o', 'g', 'g', 'br', 'o', 'g', 'o', 'o', 'b', 'o', 'y', 'o', 'y', 'o', 'y', 'g', 'g', 'g', 'v', 'r', 'g', 'br', 'o', 'br', 'g', 'o', 'o', 'y', 'br', 'g', 'o', 'g', 'g', 'y', 'o', 'g', 'o', 'g', 'g', 'v', 'o', 'y', 'br', 'y', 'v', 'r', 'br', 'o', 'b', 'v', 'g', 'v', 'v', 'g', 'g', 'br', 'g', 'br', 'g', 'y', 'br', 'g', 'g', 'g', 'br', 'g', 'g', 'g', 'g', 'br', 'g', 'o', 'y', 'g', 'g', 'v', 'y', 'g', 'v', 'v', 'g', 'br', 'y', 'v', 'br', 'g', 'b', 'y', 'b', 'g', 'g', 'b', 'b', 'g', 'g', 'v', 'br', 'br', 'o', 'br', 'br', 'br', 'g', 'o', 'r', 'br', 'r', 'g', 'br', 'y', 'b', 'r', 'b', 'g', 'br', 'g', 'r', 'b', 'g', 'g', 'g', 'r', 'b', 'br', 'b', 'g', 'y', 'v', 'g', 'r', 'r', 'y', 'g', 'b', 'g', 'o', 'br', 'g', 'br', 'g', 'br', 'br', 'br', 'br', 'br', 'v', 'v', 'o', 'br', 'g', 'y', 'v', 'b', 'v', 'br', 'o', 'o', 'g', 'y', 'y', 'b', 'o', 'v', 'o', 'v', 'b', 'g', 'o', 'br', 'v', 'y', 'g', 'br', 'r', 'b', 'o', 'g', 'g', 'g', 'g', 'g', 'g', 'v', 'g', 'y', 'g', 'br', 'g', 'o', 'o', 'br', 'o', 'y', 'g', 'br', 'y', 'y', 'g', 'y', 'y', 'v', 'y', 'g', 'g', 'br', 'br', 'g', 'r', 'o', 'br', 'g', 'br', 'br', 'g', 'r', 'g', 'b', 'g', 'g', 'r', 'g', 'y', 'g', 'br', 'v', 'g', 'br', 'v', 'o', 'g', 'r', 'b', 'g', 'g', 'y', 'o', 'v', 'g', 'br', 'br', 'o', 'br', 'g', 'y', 'y', 'v', 'br', 'g', 'v', 'g', 'g', 'g', 'g', 'br', 'g', 'br', 'g', 'br', 'br', 'g', 'o', 'v', 'g', 'o', 'g', 'v', 'b', 'r', 'br', 'r', 'br', 'r', 'br', 'v', 'g', 'g', 'br', 'v', 'y', 'g', 'y', 'g', 'r', 'g', 'y', 'v', 'g', 'v', 'g', 'r', 'g', 'g', 'g', 'y', 'v', 'g', 'v', 'r', 'o', 'g', 'br', 'g', 'v', 'o', 'y', 'g', 'v', 'o', 'b', 'b', 'y', 'g', 'g', 'o', 'br', 'v', 'r', 'y', 'y', 'g', 'r', 'y', 'g', 'y', 'o', 'v', 'y', 'b', 'g', 'r', 'r', 'o', 'v', 'o', 'br', 'b', 'v', 'o', 'v', 'y', 'br', 'br', 'g', 'r', 'y', 'v', 'b', 'y', 'r', 'br', 'g', 'g', 'g', 'y', 'g', 'o', 'g', 'br', 'g', 'br', 'g', 'g', 'br', 'g', 'g', 'o', 'g', 'b', 'y', 'o', 'o', 'g', 'v', 'br', 'o', 'o', 'o', 'br', 'br', 'br', 'br', 'g', 'y', 'y', 'y', 'y', 'v', 'g']."
     ]
    }
   ],
   "source": [
    "nx.draw_networkx(G, with_labels=False, node_size=50, node_color=c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'draw_graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-481ad1c1771c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'draw_graphviz'"
     ]
    }
   ],
   "source": [
    "nx.draw_graphviz(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2, 565], dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_to_tuple(adj)[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from networkx import karate_club_graph, to_numpy_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zkc = karate_club_graph()\n",
    "order = sorted(list(zkc.nodes()))\n",
    "A = to_numpy_matrix(zkc, nodelist=order)\n",
    "I = np.eye(zkc.number_of_nodes())\n",
    "A_hat = A + I\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
    "D_hat = np.matrix(np.diag(D_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 1., 1., ..., 1., 0., 0.],\n",
       "        [1., 1., 1., ..., 0., 0., 0.],\n",
       "        [1., 1., 1., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 1., 1., 1.],\n",
       "        [0., 0., 1., ..., 1., 1., 1.],\n",
       "        [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_te' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-1db265d75d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_te' is not defined"
     ]
    }
   ],
   "source": [
    "X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
